{{- /*
RayService for SGLang (GPU LLM) â€” defensive and values-driven.
This version defines locals up-front to avoid nested/function-paren bugs.
Renders only when .Values.rayservices.sglang.enabled == true
*/ -}}
{{- $root := . -}}
{{- $vals := $root.Values.rayservices.sglang | default dict -}}
{{- if not (default false $vals.enabled) -}}
{{- else -}}

{{- /* locals and safe defaults */ -}}
{{- $ray := $vals.ray | default dict -}}
{{- $rayHead := $ray.head | default dict -}}
{{- $rayWorkers := $ray.workers | default dict -}}
{{- $worker := $vals.worker | default dict -}}
{{- $svc := $vals.service | default dict -}}

{{- $rw_cpu := default dict (index $rayWorkers "cpu") -}}
{{- $w_cpu := default dict (index $worker "cpu") -}}
{{- $rw_mem := default dict (index $rayWorkers "memory") -}}
{{- $w_mem := default dict (index $worker "memory") -}}
{{- $rw_gpu := default dict (index $rayWorkers "gpu") -}}
{{- $w_gpu := default dict (index $worker "gpu") -}}

{{- $minReplicas := default 1 (or (index $rayWorkers "minReplicas") (index $worker "minReplicas")) -}}
{{- $maxReplicas := default 4 (or (index $rayWorkers "maxReplicas") (index $worker "maxReplicas")) -}}

{{- $headCpuReq := default "1000m" (or (index $rayHead "cpu").request (index $rayHead "cpu").request) -}}
{{- $headMemReq := default "4Gi" (or (index $rayHead "memory").request (index $rayHead "memory").request) -}}

{{- $workerCpuReq := default "1000m" (or (index $rw_cpu "request") (index $w_cpu "request")) -}}
{{- $workerMemReq := default "8Gi" (or (index $rw_mem "request") (index $w_mem "request")) -}}
{{- $workerGpuReq := default 1 (or (index $rw_gpu "request") (index $w_gpu "request")) -}}

apiVersion: ray.io/v1
kind: RayService
metadata:
  name: {{ default "rag8s-sglang-serve" $vals.name | quote }}
  namespace: {{ default (include "rag8s.namespace" $root) $vals.namespace | quote }}
  labels:
    app.kubernetes.io/name: sglang
    app.kubernetes.io/instance: {{ $root.Release.Name | quote }}
    {{- include "rag8s.labels" $root | nindent 4 }}
spec:
  rayClusterConfig:
    rayVersion: {{ default "2.10.0" $vals.ray.version | quote }}

    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
      template:
        metadata:
          annotations:
            {{- if $vals.head.annotations }}
{{ toYaml $vals.head.annotations | nindent 12 }}
            {{- end }}
        spec:
          serviceAccountName: {{ default "ray-inference-sa" $vals.serviceAccountName | quote }}
          {{- if $vals.imagePullSecrets }}
          imagePullSecrets:
{{ toYaml $vals.imagePullSecrets | nindent 12 }}
          {{- end }}
          {{- $headNodeSel := default (dict "karpenter.sh/provisioner-name" "cpu-provisioner" "kubernetes.io/arch" "amd64") $vals.head.nodeSelector }}
          nodeSelector:
{{ toYaml $headNodeSel | indent 12 }}
          {{- $headTols := default list $vals.head.tolerations }}
          {{- if $headTols }}
          tolerations:
{{ toYaml $headTols | indent 12 }}
          {{- end }}
          {{- if $vals.head.affinity }}
          affinity:
{{ toYaml $vals.head.affinity | indent 12 }}
          {{- end }}

          containers:
            - name: ray-head
              image: "{{ default (printf "%s:%s" $vals.ray.image.repository $vals.ray.image.tag) (printf "rayproject/ray:%s" (default "2.10.0" $vals.ray.version)) }}"
              imagePullPolicy: {{ default "IfNotPresent" $vals.ray.image.pullPolicy }}
              env:
                - name: RAY_NODE_ROLE
                  value: "head"
                - name: RAY_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
                {{- if $vals.env }}
{{ toYaml $vals.env | indent 16 }}
                {{- end }}
              resources:
                requests:
                  cpu: {{ $headCpuReq | quote }}
                  memory: {{ $headMemReq | quote }}
                limits:
                  cpu: {{ default (index $rayHead "cpu").limit "2000m" | quote }}
                  memory: {{ default (index $rayHead "memory").limit "8Gi" | quote }}
              ports:
                - containerPort: 8265
                - containerPort: 8000
                - containerPort: 9000
              volumeMounts:
                - name: model-volume
                  mountPath: {{ default "/opt/models" $vals.modelMountPath | quote }}
              readinessProbe:
                httpGet:
                  path: /
                  port: 8265
                initialDelaySeconds: 15
                periodSeconds: 10
              livenessProbe:
                httpGet:
                  path: /
                  port: 8265
                initialDelaySeconds: 60
                periodSeconds: 30

          volumes:
            - name: model-volume
              emptyDir: {}

    workerGroupSpecs:
      - groupName: gpu-workers
        minReplicas: {{ $minReplicas }}
        maxReplicas: {{ $maxReplicas }}
        template:
          metadata:
            annotations:
              {{- if $vals.worker.annotations }}
{{ toYaml $vals.worker.annotations | nindent 14 }}
              {{- end }}
          spec:
            {{- $workerSA := default $vals.serviceAccountName "ray-inference-sa" }}
            {{- if $workerSA }}
            serviceAccountName: {{ $workerSA | quote }}
            {{- end }}
            {{- if $vals.imagePullSecrets }}
            imagePullSecrets:
{{ toYaml $vals.imagePullSecrets | nindent 14 }}
            {{- end }}

            {{- $workerNodeSel := default (dict "karpenter.sh/provisioner-name" "gpu-provisioner" "kubernetes.io/arch" "amd64") $vals.worker.nodeSelector }}
            nodeSelector:
{{ toYaml $workerNodeSel | indent 14 }}

            {{- $workerTols := default (list (dict "key" "nvidia.com/gpu" "operator" "Exists" "effect" "NoSchedule")) $vals.worker.tolerations }}
            tolerations:
{{ toYaml $workerTols | indent 14 }}

            {{- if $vals.worker.affinity }}
            affinity:
{{ toYaml $vals.worker.affinity | indent 14 }}
            {{- end }}

            containers:
              - name: ray-gpu-worker
                image: "{{ default (printf "%s:%s" $vals.ray.image.repository $vals.ray.image.tag) (printf "rayproject/ray:%s" (default "2.10.0" $vals.ray.version)) }}"
                imagePullPolicy: {{ default "IfNotPresent" $vals.ray.image.pullPolicy }}
                env:
                  - name: RAY_NODE_ROLE
                    value: "worker"
                  - name: RAY_NAMESPACE
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.namespace
                  {{- if $vals.env }}
{{ toYaml $vals.env | indent 18 }}
                  {{- end }}
                resources:
                  requests:
                    cpu: {{ $workerCpuReq | quote }}
                    memory: {{ $workerMemReq | quote }}
                    nvidia.com/gpu: {{ $workerGpuReq }}
                  limits:
                    cpu: {{ default (index $rw_cpu "limit") (index $w_cpu "limit") | default "2000m" | quote }}
                    memory: {{ default (index $rw_mem "limit") (index $w_mem "limit") | default "16Gi" | quote }}
                    nvidia.com/gpu: {{ default (index $rw_gpu "limit") (index $w_gpu "limit") | default 1 }}
                ports:
                  - containerPort: 8000
                  - containerPort: 9000
                volumeMounts:
                  - name: model-volume
                    mountPath: {{ default "/opt/models" $vals.modelMountPath | quote }}
            readinessProbe:
              httpGet:
                path: /
                port: 8265
              initialDelaySeconds: 15
              periodSeconds: 15
              failureThreshold: 6
            volumes:
              - name: model-volume
                emptyDir: {}

  serveConfigV2: |
    applications:
      - name: sglang-app
        import_path: {{ $vals.importPath | default "rayserve-sglang" | quote }}
        runtime_env:
          working_dir: {{ $vals.runtimeWorkingDir | default "/app" | quote }}
        deployments:
          - name: SGLangService
            route_prefix: "/sglang"
            ray_actor_options:
              num_gpus: {{ default 1 (index $svc "numGPUs") }}
            autoscaling_config:
              min_replicas: {{ default 1 (index $svc "autoscale" "minReplicas") | default 1 }}
              max_replicas: {{ default 4 (index $svc "autoscale" "maxReplicas") | default 4 }}
              target_num_ongoing_requests_per_replica: {{ default 5 (index $svc "autoscale" "targetRequestsPerReplica") | default 5 }}
{{- end }}
